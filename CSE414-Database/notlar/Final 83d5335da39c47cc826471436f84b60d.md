# Final

# SQL

### Insert example

```sql
INSERT INTO tablename(column1,column2) VALUES ('VALUE1',VALUE2);
```

### Update example

```sql
UPDATE tablename SET column1='VALUE1', column2=VALUE2 WHERE cond;
```

### Delete example

```sql
DELETE FROM tablename WHERE cond;
```

### Count example

```sql
SELECT COUNT (column_name) FROM tablename WHERE cond;
```

### Average example

```sql
SELECT AVG (column_name) FROM tablename WHERE cond;
```

### Sum example

```sql
SELECT SUM (column_name) FROM tablename WHERE cond;
```

### In example

In operator allows you to specify multiple values in a where clause

```sql
SELECT columnname FROM tablename WHERE columnname IN (value1,value2);
SELECT columnname FROM tablename WHERE columnname IN (
	SELECT columnname FROM tablename WHERE columnname IN (value1,value2)
);
```

### Between example

```sql
SELECT columname FROM tablename WHERE columname BETWEEN value1 AND value2
```

### Alias column example

```sql
SELECT columname AS alias FROM tablename
```

### Alias table example

```sql
SELECT columname FROM tablename AS aliasname
```

### Join example

Used to combine rows from two or more tables based on a related column between them.

### Natural join example

Match two tuples with the same values for all common attributes. retain only oone copy of each common column.

```sql
select name, course_id from student, takes where student.ID = takes.ID;
```

is respective for

```sql
select name,course_id
from student
natural join takes;
```

### Inner join example

Returns records that have matching values in both tables.

```sql
SELECT Orders.OrderID, Customers.CustomerName, Orders.OrderDate
FROM Orders
INNER JOIN Customers ON Orders.CustomerID = CustomerID;
```

After on, give where statement to relate two tables. CustomerID is common column on these two tables.

![Untitled](Final%2083d5335da39c47cc826471436f84b60d/Untitled.png)

### Inner join example 2

```sql
SELECT Orders.OrderID, Customers.CustomerName, Shippers.ShipperName
FROM ((Orders
INNER JOIN Customers ON Orders.CustomerID = Customers.CustomerID)
INNER JOIN Shippers ON Orders.ShipperID = Shippers.ShipperID);
```

### Left (outer) join example

Returns all records from the left table, and the matched records from the right table

```sql
SELECT columname
FROM tablename 
LEFT JOIN tablename2 ON tablename1.columnname = tablename2.columname
```

### Outer join example

An extension of the join operation that avoids loss of information

Computes the join and then adds tuples form one relation that does not match tuples in the other relation to the result of the join. Uses null values.

### Right (outer) join

Returns all records from the right table, and the matched records from the left table.

```sql
SELECT columname
FROM tablename
RIGHT JOIN tablename2 ON tablename1.columname = tablename2.columname
```

### Full (outer join)

Returns all records when there is a match in either left or right table.

```sql
SELECT columname
FROM table1
FULL OUTER JOIN table2
ON table1.columname = table2.columname
WHERE cond
```

### Self join example

Self join is join the table itself, using same two tables with the from

### Union

```sql
SELECT ..
UNION
SELECT ..
```

selects only distinct values, to prevent it use UNION ALL

### Group By

Groups rows that have the same values into summary rows. like : Find the number of customers in each country

```sql
SELECT COUNT(CustomerID), Country
FROM Customers
GROUP BY Country
ORDER BY COUNT (CustomerID) DESC;
```

### Having Example

Where clause cannot used with aggregate functions

```sql
SELECT columname
FROM tablename
WHERE cond
GROUP BY columname
HAVING cond
ORDER BY columnname
```

### Procedures

Prepared SQL code that can be used again. You can pass parameter

```sql
CREATE PROCEDURE name (IN parameter INT,...)
BEGIN
STATEMENT
END

```

### Views

Creating virtual table

```sql
CREATE VIEW view_name AS
SELECT column1, column2, ...
FROM table_name
WHERE condition;
```

### Triggers

Trigger is a statement that is executed automatically by the system as a side effect of a modification to the database.

```sql
create trigger name_trigger after update of takes on (grade)
referencing new row as nrow
referencing old row as orow
for each row
when ...
begin atomic 
update
end
```

### Superkey

If values for K are suffcient to identify a unique tuple of each possible relation R, then K is a superkey.

### Candidate Key

Superkey K is a candidate key if K is minimal.

### Primary Key

One of the candidate keys is selected to be the primary key

### Foreign Key

Value in one relation must appear in another.

Initialized with referencing and referenced.

### Creating table

```sql
create table instructor(
	IDchar(5),
	name varchar(20) not null,
	dept_name varchar(20),
	salarynumeric(8,2),
	primary key (ID),
	foreign key (dept_name) references department
);
```

### ER Diagram properties

- rectangle → entity set
- list inside rectangle → attributes
- underline → primary key

![Untitled](Final%2083d5335da39c47cc826471436f84b60d/Untitled%201.png)

- draw line between related entities among the tables

![Untitled](Final%2083d5335da39c47cc826471436f84b60d/Untitled%202.png)

- diamond represent relationship set

![Untitled](Final%2083d5335da39c47cc826471436f84b60d/Untitled%203.png)

- if you have a relationship set with an attribute draw it together with the diamond

![Untitled](Final%2083d5335da39c47cc826471436f84b60d/Untitled%204.png)

- directed line (→) one
- undirected line (—) many

![Untitled](Final%2083d5335da39c47cc826471436f84b60d/Untitled%205.png)

![Untitled](Final%2083d5335da39c47cc826471436f84b60d/Untitled%206.png)

- double rectangle → weak entity set
- dashed line → discriminator of a weak entity set
- double diamond → relationship connecting the weak entity set to the identify strong entity set

![Untitled](Final%2083d5335da39c47cc826471436f84b60d/Untitled%207.png)

![Untitled](Final%2083d5335da39c47cc826471436f84b60d/Untitled%208.png)

![Untitled](Final%2083d5335da39c47cc826471436f84b60d/Untitled%209.png)

### Weak entity

One whose existence is dependent on another entity called its identifying entity

### Decomposition

Process of breaking down a database table into multiple smaller tables to improve data organization and reduce redundancy.

**Lossy decomposition** : May result in some loss of information during the decomposition process. It allows for the elimination of certain attributes or  functional dependencies. It is not possible to reconstruct the table. If we got the cartesian product of the tables, we should get the original tables subset as a result

![Untitled](Final%2083d5335da39c47cc826471436f84b60d/Untitled%2010.png)

**Lossless decomposition** : Lossless decomposition ensures that no information is lost during the decomposition. Original table can be reconstructed. If we got the cartesian product of the tables, we should get the original table as a result

![Untitled](Final%2083d5335da39c47cc826471436f84b60d/Untitled%2011.png)

Let R be a relation schema and R1 and R2 form a decomposition of R. R = R1 union R2

### Functional Dependency

Some of the constraints that are expected to holds in a db.

### Redefinition of superkey and candidate key with functional dependency

K is a superkey for relation schema R iff K → R

K is a candidate key for R iff K → R, and for no a is subset of K, a → R

### Trivial functional dependency

If it is satisfied by all instances of a relation, then it is trivial

a → B is trivial if B is a subset of a

### 

### Dependency Preservation

A decomposition that makes functional dependency unhold for a relation is said to be not dependency preserving

### Normalization

Technique used to design databases in a such a way that data redundancy and anomalies are minimized. Each relation is in good form and the decomposition is a lossless decomposition.

### BCNF

A relation schema R is in BCNF with respect to a set F of functional dependencies if for all functional dependencies in F of the form : 

a → b

where a is a subset of R and b is a subset of R, at least one of the following holds :

- a → b is trivial (ex : b is a subset of a)
- a is a superkey for R

If it is not BCNF, to make it BCNF : 
Decompose R into

- (a union b)
- (R - (b-a))

![Untitled](Final%2083d5335da39c47cc826471436f84b60d/Untitled%2012.png)

### 3NF

A relation schema R is in 3NF if for all 

a → b in F

at least one of the following holds : 

- a → b is trivial
- a is a superkey for R
- Each attribute A in b - a is contained in a candidate key for R

If a relation is in BCNF , it is in 3NF.

### Closure of a set of functional dependencies

Given a set F set of functional dependencies, there are certain other functional dependencies that are logically implied by F.

If A → B and B→C , then we can infer that A→ C

The set of all functional dependencies logically implied by F is the closure of F.

### Armstrongs Axioms

- Reflexive rule : if B is a subset of a, then a → B
- Augmention rule : if a → b then g a → g B
- Transitivity rule : if a → b and b → g, then a → g
- Union rule : if a →b holds and a → g holds, then a → b g holds
- Decomposition rule : if a→b g holds, then a → b holds and a → g holds
- Pseudotransitivity rule : If a →b holds and g b → s holds , then a g → s holds

![Untitled](Final%2083d5335da39c47cc826471436f84b60d/Untitled%2013.png)

![Untitled](Final%2083d5335da39c47cc826471436f84b60d/Untitled%2014.png)

![Untitled](Final%2083d5335da39c47cc826471436f84b60d/Untitled%2015.png)

### Canonical Cover

If update violates functional dependencies, then these functional dependencies should be in a set called canonical cover. To define it ,we first define extraneous attributes.

A canonical cover for F is a set of dependencies Fc such that

- F logically implies all dependencies Fc
- Fc logically implies all dependencies in F
- No functional dependency in Fc contains an extraneous attribute
- Each left side of functional dependency in Fc is unique. Means :

a1 → b1 and a2→b2 such that a1 = a2.

![Untitled](Final%2083d5335da39c47cc826471436f84b60d/Untitled%2016.png)

![Untitled](Final%2083d5335da39c47cc826471436f84b60d/Untitled%2017.png)

### Extraneous attribute

If we can remove an attribute without changing the functional dependency set F+, then it is extraneous attribute.

![Untitled](Final%2083d5335da39c47cc826471436f84b60d/Untitled%2018.png)

![Untitled](Final%2083d5335da39c47cc826471436f84b60d/Untitled%2019.png)

### Dependency Preservation - not use this rule

![Untitled](Final%2083d5335da39c47cc826471436f84b60d/Untitled%2020.png)

### Test for Dependency Preservation

![Untitled](Final%2083d5335da39c47cc826471436f84b60d/Untitled%2021.png)

### BCNF Decomposition algo

![Untitled](Final%2083d5335da39c47cc826471436f84b60d/Untitled%2022.png)

### Indexing

Used to speed up access to desired data

### Search key

attribute to set of attributes used to look up records in a file

### Index file

consists of records of the form

### Ordered indices

Search keys are stored in sorted order

### Hash indices

Search keys are distributed uniformly using hash functions

### Metrics

- Access type : specified value or range of values
- Access time
- Insertion time
- Deletion time
- Space overhead

### Ordered indices

- Clustering index : In sequantially orderded file, index whose search key specifies the sequential order of the file . Also called primary index.
- Secondary index : Whose search key specifies an order different from the sequential order of the file. Also called nonclustering index
- Index sequential file : Sequential file ordered on a search key, with a clustering index on the search key.

### Dense Index files

Index record appears for every search key value in the file

### Sparse Index file

Contains index records for only some search key values.

- Applicable when records are sequentially ordered on search key
- Less space and less maintanence overhead for insertions and deletions
- Generally slower than dense index.

### Secondary Indices Example

![Untitled](Final%2083d5335da39c47cc826471436f84b60d/Untitled%2023.png)

Index record points to a bucket that contains pointers to all the actual records with that particular search key value

### Multilevel index

If index does not fit in memory, access becomes expensive.

Solution : treat index kept on disk as sequential file and construct a sparse index on it.

- outer index : a sparse index of the basic index
- inner index : the basic index file

Indices at all levels must be updated on insertion or deletion from the file

![Untitled](Final%2083d5335da39c47cc826471436f84b60d/Untitled%2024.png)

### B-Tree

![Untitled](Final%2083d5335da39c47cc826471436f84b60d/Untitled%2025.png)

### Static hashing

A bucket is a unit of storage containing one or more entries. A bucket is typically a disk block

We obtain the bucket of an entry from its search key value using a hash function

![Untitled](Final%2083d5335da39c47cc826471436f84b60d/Untitled%2026.png)

In static hashing function h maps search key values to a fixed  set of B of bucket addresses. Database grow or shrink with time.

Periodic reorganization is maybe a solution.

better one : allow the number of buckets to be modified dynamically.

### Dynamic hashing

- Periodic rehashing : if number of entries in a hash table becomes 1.5 times size of hash table
    - create new hash table of size 2 times size of the previous hash table
    - rehash all entries to new table
- Linear hashing
    - Do rehashing in an incremental manner
- Extendable hashing
    - Tailored to disk based hashing

### Index creation

```sql
create index takes_pk on takes (...)
drop index
```

### Query Processing

### Basic Steps

- Parsing and translation
- Optimization
- Evaluation

### Parsing and Translation

- Translate the query into its internal form. Then translate into relational algebra
- Checks syntax, verifies relations

### Optimization

A relational algebra expression may have many equivalent expressions.

Amongst all equivalent evaluation plans choose the one with lowest cost.

### Evaluation

- Query execution engine takes a query evaluation plan. Execute that plan and return answer to the query.

### Transaction

Transaction is a unit of program execution that accesses and possibly updates various data items

ACID

- Atomicity : could not be half operation, commit or rollback
- Consistency : all data should be always consistent
- Isolation : Each transaction must be unaware of other concurrently executing transactions.
- Durability : After a transaction completes successfulyy, the changes it has made to the database persist, even if there are system failures

### Transaction states

- Active : initial state
- Partially commited : after the final statement has been executed
- Failed : failed
- Aborted : After the transaction has been rolled back
- Commited : after successful operation

### NoSQL

Data is more semi structured

Large data volumes

Scalabke replication and distribution

ACID transaction properties are not needed. BASE is used (Basically Available, Soft State, Eventually Consistent)

### NoSQL Database Types :

- Sorted ordered Column Store
    - efficiently stored
    - avoid consuming space for storing nulls

![Untitled](Final%2083d5335da39c47cc826471436f84b60d/Untitled%2027.png)

- Document databases
    - pair each key with a document
- Key-value Store

![Untitled](Final%2083d5335da39c47cc826471436f84b60d/Untitled%2028.png)

- Graph Databases
    - stored as an edge, a node or an attribute

![Untitled](Final%2083d5335da39c47cc826471436f84b60d/Untitled%2029.png)

### SQL vs NoSQL

| SQL | NoSQL |
| --- | --- |
| Relational Model | Non-relational Model |
| Structured table - data | Semi structured - data |
| Strict schema | Dynamic schema |
| ACID - transaction | Mosly BASE, few ACID |
| Strong consistency | Eventual to strong |
| Vertically by upgrading hardware (scale) | Horizontally by data partitioning (scale) |
|  |  |

### Document Database

JSON, key value pair

### Scaling RDBMS

### Master - Slave

- All writes are written to the master. All reads performed against the replicated slave databases. Critical reads may be incorrect as writes may not have been propogated down.
- Large datasets can pose problems as master needs to duplicate data to

### Sharding

- Any DB distributed across multiple machines needs to know in what machine a piece of data is stored or must be stored.

![Untitled](Final%2083d5335da39c47cc826471436f84b60d/Untitled%2030.png)

### CAP Theorem

A logical way for assessing the problems involved in ACID like guarantees in distributed systems is provided by the cap theorem

- Consistency
- Availability
- Partition tolerance

At most two of the following three can be maximized at one time

![Untitled](Final%2083d5335da39c47cc826471436f84b60d/Untitled%2031.png)

![Untitled](Final%2083d5335da39c47cc826471436f84b60d/Untitled%2032.png)

![Untitled](Final%2083d5335da39c47cc826471436f84b60d/Untitled%2033.png)

# Çıkmış Sorular

## 1)

### a) What are functional dependencies and why do we need them in database design? What is database closure? Give and example and explain

Functional dependencies are constraints that describe the relationships between attributes in database table. They are important because : 

- Ensures data integrity : enforces data consistency.
- Normalization : if table is not normalized, we use functional dependencies to normalize it.

Database closure refers to the complete set of attributes that can be determined from a given set of attributes based on the functional dependencies in a relation.

Consider a relation with the following functional dependencies:

1. A -> BC
2. BC -> D
3. D -> E

We want to find the closure of the attribute set {A}.

Step 1: Start with the given attribute set: {A}.
Step 2: Apply the functional dependencies:

- Using dependency 1 (A -> BC), we can add B and C to the set: {A, B, C}.
- Using dependency 2 (BC -> D), we can add D to the set: {A, B, C, D}.
- Using dependency 3 (D -> E), we can add E to the set: {A, B, C, D, E}.

The closure of {A} based on the given functional dependencies is {A, B, C, D, E}. This means that the attributes B, C, D, and E can be determined or inferred from the attribute A using the provided functional dependencies.

### b)What is a multilevel index? Explain and draw an example graph

If index does not fit in memory, access becomes expensive.

Index entries are organized hierarchially into multiple levels. Each level contains index blocks that point to next level, leading to the actual data blocks. The root level, provides an entry point to access the lower levels.

Indices at all levels must be updated on insertion or deletion from the file

![Untitled](Final%2083d5335da39c47cc826471436f84b60d/Untitled%2024.png)

### c) What is 3NF normalization? Give an example with before and after 3NF normalization.

A normalization technique that aims to eliminate redundant data. A relation schema is said to be in 3NF, if for every nontrivial functional dependency a→ in the relations function dependencies F, one of the following should be satisfied : 

- a → b is trivial
- a is a superkey for relation
- Each attribute A in b - a is contained a candidate key for the relation

Example …

### d) What is the query processing steps? Draw the graph and explain each of them.

Basic Steps

- Parsing and translation
- Optimization
- Evaluation

Parsing and Translation

- Translate the query into its internal form. Then translate into relational algebra
- Checks syntax, verifies relations

Optimization

A relational algebra expression may have many equivalent expressions.

Amongst all equivalent evaluation plans choose the one with lowest cost.

Evaluation

- Query execution engine takes a query evaluation plan. Execute that plan and return answer to the query.

### e)What is a data cube? How is it different from database? Explain

A data cube is a data structure used to store data and do a multidimensional analysis of the data. Provides a way to organize and represent data in a format that allows for efficient and flexible analysis from multiple perspectives.

## 2)

table : 

![Untitled](Final%2083d5335da39c47cc826471436f84b60d/Untitled%2034.png)

### a) Give an SQL query that lists salary averages for each job type, whose average salary is more than 2000. If it less than 2000, don’t show it. (10 points)
Employee (id, name, department, salary, job)

```sql
SELECT avg(salary)
FROM employee
GROUP BY dept_name
HAVING avg(salary) > 2000
```

### b) What is a check constraint? Give an SQL query that uses a check constraint. (10 points)

Check constraint is a constraint that defines a condition that must be satisfied for the data in a column or a table. It ensures that the data meets spesific criteria. Also prevents inseriton and deletion data that violates the condition.

```sql
CREATE TABLE Employees (
    EmployeeID INT PRIMARY KEY,
    FirstName VARCHAR(50),
    LastName VARCHAR(50),
    Age INT,
    Salary DECIMAL(10, 2),
    EmploymentStatus VARCHAR(20),
    CONSTRAINT CHK_EmploymentStatus CHECK (EmploymentStatus IN ('Full-time', 'Part-time', 'Contractor'))
);
```

### c) Using the Employee and Department tables below, write SQL queries with INNER JOIN, LEFT JOIN,

```sql
SELECT Employee.name, Department.dept_name
FROM Employee
INNER JOIN Department ON Employee.department = Department.dept_id;
```

+--------+-----------+
| name   | dept_name |
+--------+-----------+
| John   | Sales     |
| Jane   | IT        |
| Bob    | Sales     |
| Alice  | HR        |
+--------+-----------+

```sql
SELECT Employee.name, Department.dept_name
FROM Employee
LEFT JOIN Department ON Employee.department = Department.dept_id;
```

+--------+-----------+
| name   | dept_name |
+--------+-----------+
| John   | Sales     |
| Jane   | IT        |
| Bob    | Sales     |
| Alice  | HR        |
+--------+-----------+